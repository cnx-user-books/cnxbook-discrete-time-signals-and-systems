<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Eigenanalysis of LTI Systems (Finite-Length Signals)</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m57681</md:content-id>
  <md:title>Eigenanalysis of LTI Systems (Finite-Length Signals)</md:title>
  <md:abstract/>
  <md:uuid>afae700e-90dd-4c27-8ffa-b9def44c3abb</md:uuid>
</metadata>

<content>
    <para id="delete_me">In the study of discrete-time signals and systems, concepts from linear algebra often provide additional insight. When it comes to LTI systems, a certain area of linear algebra is particularly helpful: eigenanalysis.  </para>
    <section id="idm91539804528">
      <title>Eigenvectors and Eigenvalues</title>
      <para xmlns:m="http://www.w3.org/1998/Math/MathML" id="idm91539803984">Given a square matrix (one that has the same number of rows as columns) <m:math><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math>, a vector <m:math><m:semantics><m:mi>v</m:mi><m:annotation encoding="math/tex">v</m:annotation></m:semantics></m:math> is an eigenvector with corresponding scalar eigenvalue <m:math><m:semantics><m:mi>λ</m:mi><m:annotation encoding="math/tex">\lambda</m:annotation></m:semantics></m:math> if:
<m:math><m:semantics><m:mrow><m:mi>A</m:mi><m:mi>v</m:mi><m:mo>=</m:mo><m:mi>λ</m:mi><m:mi>v</m:mi></m:mrow><m:annotation encoding="math/tex">Av=\lambda v</m:annotation></m:semantics></m:math>. There is a geometric interpretation to this eigenanalysis of the matrix <m:math><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math>. Multiplying a matrix by one of its eigenvectors produces simply a scaled version of that same eigenvector (scaled by a factor of <m:math><m:semantics><m:mi>λ</m:mi><m:annotation encoding="math/tex">\lambda</m:annotation></m:semantics></m:math>), so a matrix multiplication of an eigenvector does not change its orientation, only its strength.</para><para id="eip-913">Consider this example in two dimensions, a square matrix <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math>:</para>
      <para id="idm91539790928"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>A</m:mi><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:annotation encoding="math/tex">A=\begin{bmatrix}3 &amp; 1 \\ 1 &amp; 3\end{bmatrix}</m:annotation></m:semantics></m:math>,</para>
      <para id="idm91539782496"> and the vector <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>v</m:mi><m:annotation encoding="math/tex">v</m:annotation></m:semantics></m:math>:</para>
      <para id="idm91539780864"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>v</m:mi><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:annotation encoding="math/tex">v=\begin{bmatrix}1 \\-1\end{bmatrix}</m:annotation></m:semantics></m:math>.</para>
      <para id="idm91539774176">Note what happens when we multiply the matrix <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math> by the vector <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>v</m:mi><m:annotation encoding="math/tex">v</m:annotation></m:semantics></m:math>:
</para>
      <para id="idm91539771168"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><m:mtr><m:mtd><m:mi>A</m:mi><m:mi>v</m:mi></m:mtd><m:mtd><m:mi/><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mo stretchy="false">(</m:mo><m:mn>3</m:mn><m:mo>−</m:mo><m:mn>1</m:mn><m:mo stretchy="false">)</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mo stretchy="false">(</m:mo><m:mn>1</m:mn><m:mo>−</m:mo><m:mn>3</m:mn><m:mo stretchy="false">)</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:mn>2</m:mn><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:mn>2</m:mn><m:mi>v</m:mi></m:mtd></m:mtr></m:mtable><m:annotation encoding="math/tex">\begin{align*}
Av&amp;=\begin{bmatrix}3 &amp; 1 \\ 1 &amp; 3 \end{bmatrix}\begin{bmatrix}1 \\ -1\end{bmatrix}\\
&amp;=\begin{bmatrix}(3-1) \\ (1-3)\end{bmatrix}\\
&amp;=\begin{bmatrix}2 \\ -2\end{bmatrix}\\
&amp;=2\begin{bmatrix}1 \\ -1\end{bmatrix}\\
&amp;=2v
\end{align*}</m:annotation></m:semantics></m:math>. </para>
      <para id="idm91539729728">So running the vector <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>v</m:mi><m:annotation encoding="math/tex">v</m:annotation></m:semantics></m:math> through the matrix <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math> simply scales the vector by <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mn>2</m:mn><m:annotation encoding="math/tex">2</m:annotation></m:semantics></m:math>.</para>
    </section>
    <section id="idm91539725440">
      <title>Eigendecomposition: Handling Multiple Eigenvectors and Eigenvalues</title>
      <para xmlns:m="http://www.w3.org/1998/Math/MathML" id="idm91539724848">We have seen what eigvenvectors and eigenvalues are for square matrices. Now, an <m:math><m:semantics><m:mrow><m:mi>N</m:mi><m:mo>×</m:mo><m:mi>N</m:mi></m:mrow><m:annotation encoding="math/tex">N\times N</m:annotation></m:semantics></m:math> matrix will have <m:math><m:semantics><m:mi>N</m:mi><m:annotation encoding="math/tex">N</m:annotation></m:semantics></m:math> eigenvectors (not necessarily distinct), each with its own eigenvalue. We can put all of these vectors and values into their own matrices. Suppose the eigenvectors of the matrix are <m:math><m:semantics><m:mrow><m:mo fence="false" stretchy="false">{</m:mo><m:msub><m:mi>v</m:mi><m:mi>m</m:mi></m:msub><m:msubsup><m:mo fence="false" stretchy="false">}</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msubsup></m:mrow><m:annotation encoding="math/tex">\{v_m\}_{m=0}^{N-1}</m:annotation></m:semantics></m:math> and the values are <m:math><m:semantics><m:mrow><m:mo fence="false" stretchy="false">{</m:mo><m:msub><m:mi>λ</m:mi><m:mi>m</m:mi></m:msub><m:msubsup><m:mo fence="false" stretchy="false">}</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msubsup></m:mrow><m:annotation encoding="math/tex">\{\lambda_m\}_{m=0}^{N-1}</m:annotation></m:semantics></m:math>. Then we can organize all of them like this:</para><para id="idm91539704544"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>V</m:mi><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:msub><m:mi>v</m:mi><m:mn>0</m:mn></m:msub><m:mrow class="MJX-TeXAtom-ORD"><m:mo stretchy="false">|</m:mo></m:mrow><m:msub><m:mi>v</m:mi><m:mn>1</m:mn></m:msub><m:mrow class="MJX-TeXAtom-ORD"><m:mo stretchy="false">|</m:mo></m:mrow><m:mo>⋯</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mo stretchy="false">|</m:mo></m:mrow><m:msub><m:mi>v</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mspace linebreak="newline"/><m:mi mathvariant="normal">Λ</m:mi><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:msub><m:mi>λ</m:mi><m:mn>0</m:mn></m:msub></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:msub><m:mi>λ</m:mi><m:mn>1</m:mn></m:msub></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd><m:mo>⋱</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd/><m:mtd><m:msub><m:mi>λ</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:annotation encoding="math/tex">V= \begin{bmatrix}v_0 | v_1 | \cdots | v_{N-1} \end{bmatrix}\\\Lambda = \begin{bmatrix}\lambda_0 \\ &amp; \lambda_1 \\ &amp;&amp; \ddots \\ &amp;&amp;&amp; \lambda_{N-1} \end{bmatrix}</m:annotation></m:semantics></m:math>
.</para>
      <para id="idm91539677008"> With those vectors and values collected like that, we can express the eigenvector/value property <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>A</m:mi><m:mi>v</m:mi><m:mo>=</m:mo><m:mi>λ</m:mi><m:mi>v</m:mi></m:mrow><m:annotation encoding="math/tex">Av=\lambda v</m:annotation></m:semantics></m:math> for all of the eigenvectors and eigvenvalues of the matrix <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math> at once:
<m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>A</m:mi><m:mi>V</m:mi><m:mo>=</m:mo><m:mi>V</m:mi><m:mi mathvariant="normal">Λ</m:mi></m:mrow><m:annotation encoding="math/tex">AV=V\Lambda</m:annotation></m:semantics></m:math>.</para>
    </section>
    <section id="idm91539668864">
      <title>Diagonalization</title>
      <para id="idm91539668336">Now, if the square matrix <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>V</m:mi><m:annotation encoding="math/tex">V</m:annotation></m:semantics></m:math> is invertible (which will be the case if the columns of <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math> are linearly independent, which of course happens if the vectors form a basis), then we can do some special things with it.</para>
      <para xmlns:m="http://www.w3.org/1998/Math/MathML" id="eip-254">Recall the eigendecomposition relationship: <m:math><m:semantics><m:mrow><m:mi>A</m:mi><m:mi>V</m:mi><m:mo>=</m:mo><m:mi>V</m:mi><m:mi mathvariant="normal">Λ</m:mi></m:mrow><m:annotation encoding="math/tex">AV=V\Lambda</m:annotation></m:semantics></m:math>. If <m:math><m:semantics><m:mi>V</m:mi><m:annotation encoding="math/tex">V</m:annotation></m:semantics></m:math> is invertible, then we can multiply each side of the equation by <m:math><m:semantics><m:msup><m:mi>V</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:annotation encoding="math/tex">V^{-1}</m:annotation></m:semantics></m:math>:
<m:math><m:semantics><m:mrow><m:msup><m:mi>V</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mi>A</m:mi><m:mi>V</m:mi><m:mo>=</m:mo><m:msup><m:mi>V</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mi>V</m:mi><m:mi mathvariant="normal">Λ</m:mi><m:mo>=</m:mo><m:mi>I</m:mi><m:mi mathvariant="normal">Λ</m:mi><m:mo>=</m:mo><m:mi mathvariant="normal">Λ</m:mi></m:mrow><m:annotation encoding="math/tex">V^{-1}AV=V^{-1}V\Lambda=I\Lambda=\Lambda</m:annotation></m:semantics></m:math>. So <m:math><m:semantics><m:mrow><m:msup><m:mi>V</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mi>A</m:mi><m:mi>V</m:mi><m:mo>=</m:mo><m:mi mathvariant="normal">Λ</m:mi></m:mrow><m:annotation encoding="math/tex">V^{-1}AV=\Lambda</m:annotation></m:semantics></m:math>. Because multiplying <m:math><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math> by <m:math><m:semantics><m:mi>V</m:mi><m:annotation encoding="math/tex">V</m:annotation></m:semantics></m:math> on one side and <m:math><m:semantics><m:msup><m:mi>V</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:annotation encoding="math/tex">V^{-1}</m:annotation></m:semantics></m:math> on the other produces a diagonal matrix, we say that the matrix <m:math><m:semantics><m:mi>V</m:mi><m:annotation encoding="math/tex">V</m:annotation></m:semantics></m:math><emphasis effect="italics"><term> diagonalizes </term></emphasis><m:math><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math>. If we multiply the eigendecomposition matrix the other way, we will have that <m:math><m:semantics><m:mrow><m:mi>A</m:mi><m:mo>=</m:mo><m:mi>V</m:mi><m:mi mathvariant="normal">Λ</m:mi><m:msup><m:mi>V</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow><m:annotation encoding="math/tex">A=V\Lambda V^{-1}</m:annotation></m:semantics></m:math>. One of the reasons (more of which we'll see later) why we consider this diagonalization of <m:math><m:semantics><m:mi>A</m:mi><m:annotation encoding="math/tex">A</m:annotation></m:semantics></m:math> is that it is easier to matrix multiply with diagonal matrices than full ones.</para></section><section id="idm91539624672">
        <title>LTI Systems and Eigenanalysis</title>
        <para id="idm91539624128">Perhaps you may be wondering how all of this linear algebra relates to discrete-time systems. For LTI systems operating on finite-length discrete-time systems, the input output relationship is:
<m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>y</m:mi><m:mo>=</m:mo><m:mi>H</m:mi><m:mi>x</m:mi></m:mrow><m:annotation encoding="math/tex">y=Hx</m:annotation></m:semantics></m:math>,
where <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>H</m:mi><m:annotation encoding="math/tex">H</m:annotation></m:semantics></m:math> is a circulant matrix (each row being a circularly shifted version of the system impulse response <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>h</m:mi><m:annotation encoding="math/tex">h</m:annotation></m:semantics></m:math>).</para>
        <para id="eip-67">Let's see what the eigenvectors of <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>H</m:mi><m:annotation encoding="math/tex">H</m:annotation></m:semantics></m:math> are. These will be the finite-length signals that, when input into the system, emerge as outputs simply as scaled versions of themselves. In that sense, they are somehow fundamentally related to all LTI systems.</para>
        <para id="eip-497">It so happens that, remarkably, any and all LTI systems for finite-length (length <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>N</m:mi><m:annotation encoding="math/tex">N</m:annotation></m:semantics></m:math>) signals have the exact same set of eigenvectors! The eigenvectors for any LTI length-<m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>N</m:mi><m:annotation encoding="math/tex">N</m:annotation></m:semantics></m:math> system are complex harmonic sinusoids:</para>
        <para id="idm91539612384"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:msub><m:mi>s</m:mi><m:mi>k</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mi>n</m:mi><m:mo stretchy="false">]</m:mo><m:mtext> </m:mtext><m:mo>=</m:mo><m:mtext> </m:mtext><m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi></m:mrow></m:msup><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac><m:mtext> </m:mtext><m:mo>=</m:mo><m:mtext> </m:mtext><m:mfrac><m:mn>1</m:mn><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac><m:mrow><m:mo>(</m:mo><m:mi>cos</m:mi><m:mspace width="negativethinmathspace"/><m:mrow><m:mo>(</m:mo><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi><m:mo>)</m:mo></m:mrow><m:mo>+</m:mo><m:mi>j</m:mi><m:mi>sin</m:mi><m:mspace width="negativethinmathspace"/><m:mrow><m:mo>(</m:mo><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi><m:mo>)</m:mo></m:mrow><m:mo>)</m:mo></m:mrow><m:mo>,</m:mo><m:mspace width="2em"/><m:mn>0</m:mn><m:mo>≤</m:mo><m:mi>n</m:mi><m:mo>,</m:mo><m:mi>k</m:mi><m:mo>≤</m:mo><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow><m:annotation encoding="math/tex">s_k[n] ~=~ \frac{e^{j \frac{2\pi}{N}kn}}{\sqrt{N}}  ~=~ \frac{1}{\sqrt{N}}\left( \cos\!\left(\frac{2\pi}{N}kn\right) + j \sin\!\left(\frac{2\pi}{N}kn\right) \right),
\qquad 0\leq n,k \leq N-1</m:annotation></m:semantics></m:math>. </para>
        <para id="idm91539582816">So, if we have an LTI system--any LTI system--then giving an <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:msub><m:mi>s</m:mi><m:mi>k</m:mi></m:msub><m:annotation encoding="math/tex">s_k</m:annotation></m:semantics></m:math> as an input will result in the output being <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:msub><m:mi>λ</m:mi><m:mi>k</m:mi></m:msub><m:msub><m:mi>s</m:mi><m:mi>k</m:mi></m:msub></m:mrow><m:annotation encoding="math/tex">\lambda_k s_k</m:annotation></m:semantics></m:math>, with the particular values of <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:msub><m:mi>λ</m:mi><m:mi>k</m:mi></m:msub><m:annotation encoding="math/tex">\lambda_k</m:annotation></m:semantics></m:math> of course being dependent on the system:
</para>
        <figure id="Hinout"><media id="Hinout-plot" alt="Image">
            <image mime-type="image/png" src="../../media/eigeninout.png" width="600"/>
          </media>
          
        <caption>When a complex harmonic sinusoid is input into an LTI system, the output is a scaled version of the input. Here the real (cosine) and imaginary (sine) parts of the sinusoid are plotted as the input. Note how the system merely scales the inputs.</caption></figure><para id="idm91539571216">
To prove this special property of LTI systems, we simply compute the circular convolution sum for an LTI system with arbitrary impulse response <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>n</m:mi><m:mo stretchy="false">]</m:mo></m:mrow><m:annotation encoding="math/tex">h[n]</m:annotation></m:semantics></m:math> and input of the form <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi></m:mrow></m:msup><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac><m:annotation encoding="math/tex">\frac{e^{j \frac{2\pi}{N}kn}}{\sqrt{N}}</m:annotation></m:semantics></m:math>:</para>
        <para id="idm91539560912"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><m:mtr><m:mtd><m:msub><m:mi>s</m:mi><m:mi>k</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mi>n</m:mi><m:mo stretchy="false">]</m:mo><m:mo>⊛</m:mo><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>n</m:mi><m:mo stretchy="false">]</m:mo></m:mtd><m:mtd><m:mi/><m:mo>=</m:mo><m:munderover><m:mo>∑</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:munderover><m:msub><m:mi>s</m:mi><m:mi>k</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mo stretchy="false">(</m:mo><m:mi>n</m:mi><m:mo>−</m:mo><m:mi>m</m:mi><m:msub><m:mo stretchy="false">)</m:mo><m:mi>N</m:mi></m:msub><m:mo stretchy="false">]</m:mo><m:mspace width="thinmathspace"/><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>m</m:mi><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:munderover><m:mo>∑</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:munderover><m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mo stretchy="false">(</m:mo><m:mi>n</m:mi><m:mo>−</m:mo><m:mi>m</m:mi><m:msub><m:mo stretchy="false">)</m:mo><m:mi>N</m:mi></m:msub></m:mrow></m:msup><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac><m:mspace width="thinmathspace"/><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>m</m:mi><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:munderover><m:mo>∑</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:munderover><m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mo stretchy="false">(</m:mo><m:mi>n</m:mi><m:mo>−</m:mo><m:mi>m</m:mi><m:mo stretchy="false">)</m:mo></m:mrow></m:msup><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac><m:mspace width="thinmathspace"/><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>m</m:mi><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:munderover><m:mo>∑</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:munderover><m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi></m:mrow></m:msup><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>m</m:mi></m:mrow></m:msup><m:mspace width="thinmathspace"/><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>m</m:mi><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:mrow><m:mo>(</m:mo><m:munderover><m:mo>∑</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:munderover><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>m</m:mi></m:mrow></m:msup><m:mspace width="thinmathspace"/><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>m</m:mi><m:mo stretchy="false">]</m:mo><m:mo>)</m:mo></m:mrow><m:mfrac><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi></m:mrow></m:msup><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mfrac></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mi/><m:mo>=</m:mo><m:mtext> </m:mtext><m:msub><m:mi>λ</m:mi><m:mi>k</m:mi></m:msub><m:mspace width="thinmathspace"/><m:msub><m:mi>s</m:mi><m:mi>k</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mi>n</m:mi><m:mo stretchy="false">]</m:mo><m:mtext> </m:mtext><m:mo>,</m:mo><m:mtext> </m:mtext><m:msub><m:mi>λ</m:mi><m:mi>k</m:mi></m:msub><m:mo>=</m:mo><m:mrow><m:mo>(</m:mo><m:munderover><m:mo>∑</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mi>m</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:munderover><m:msup><m:mi>e</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mo>−</m:mo><m:mi>j</m:mi><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>m</m:mi></m:mrow></m:msup><m:mspace width="thinmathspace"/><m:mi>h</m:mi><m:mo stretchy="false">[</m:mo><m:mi>m</m:mi><m:mo stretchy="false">]</m:mo><m:mo>)</m:mo></m:mrow></m:mtd></m:mtr></m:mtable><m:annotation encoding="math/tex">\begin{align*}
s_k[n] \circledast h[n] &amp;=
\sum_{m=0}^{N-1} s_k[(n-m)_N]\,h[m]\\
&amp;= \sum_{m=0}^{N-1} \frac{e^{j \frac{2\pi}{N}k(n-m)_N}}{\sqrt N} \,h[m] \\
&amp;=\sum_{m=0}^{N-1} \frac{e^{j \frac{2\pi}{N}k(n-m)}}{\sqrt N} \,h[m]\\
&amp;=\sum_{m=0}^{N-1} \frac{e^{j \frac{2\pi}{N}kn}}{\sqrt N} e^{-j \frac{2\pi}{N}km} \, h[m] \\
&amp;=\left( \sum_{m=0}^{N-1}  e^{-j \frac{2\pi}{N}km} \,h[m] \right)\frac{e^{j \frac{2\pi}{N}kn}}{\sqrt N}\\
&amp;=~ \lambda_k \, s_k[n]~,~\lambda_k=\left( \sum_{m=0}^{N-1}  e^{-j \frac{2\pi}{N}km} \,h[m] \right)
\end{align*}</m:annotation></m:semantics></m:math>.</para>
        <para id="idm91539444208"> This proof reveals how we are to find the eigenvalues (<m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:msub><m:mi>λ</m:mi><m:mi>k</m:mi></m:msub><m:annotation encoding="math/tex">\lambda_k</m:annotation></m:semantics></m:math>) that correspond to each harmonic sinusoid eigenvector: they are simply the inner products of the eigenvectors with the system's impulse response. Each value <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:msub><m:mi>λ</m:mi><m:mi>k</m:mi></m:msub><m:annotation encoding="math/tex">\lambda_k</m:annotation></m:semantics></m:math> is called the system's <emphasis effect="italics">frequency response</emphasis> at frequency <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>k</m:mi><m:annotation encoding="math/tex">k</m:annotation></m:semantics></m:math>, because it indicates how the system scales inputs of that particular frequency. It is a significant enough characteristic of the system to warrant its own notation: <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>H</m:mi><m:mo stretchy="false">[</m:mo><m:mi>k</m:mi><m:mo stretchy="false">]</m:mo></m:mrow><m:annotation encoding="math/tex">H[k]</m:annotation></m:semantics></m:math>.</para>
      </section>
      <section id="idm91539433104">
        <title>Eigendecomposition of LTI Systems</title>
        <para id="idm91539432544">As with matrices in general, we can apply an eigendecomposition on an LTI system matrix. For LTI finite-length systems, these matrices are circulant:
</para>
        <figure id="yHxlti"><media id="yHxlti-plot" alt="Image">
            <image mime-type="image/png" src="../../media/yHx.png" width="300" print-width="4in"/>
          </media>
          
        </figure><para id="idm91539429264">
We have seen that the eigenvectors of LTI systems are harmonic complex sinusoids. We can stack these up into a single matrix <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mi>S</m:mi><m:annotation encoding="math/tex">S</m:annotation></m:semantics></m:math>, the entries of which are <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:msub><m:mi>S</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>n</m:mi><m:mo>,</m:mo><m:mi>k</m:mi></m:mrow></m:msub><m:annotation encoding="math/tex">S_{n,k}</m:annotation></m:semantics></m:math>, which is plotted below:
</para>
        <figure xmlns:m="http://www.w3.org/1998/Math/MathML" id="dftmtx" orient="horizontal"><subfigure id="dftcosMatrix-plot">
            <media id="dftcosMatrix" alt="Image">
              <image mime-type="image/png" src="../../media/realeigmat.png" width="200" print-width="200"/>
            </media>
            <caption>The real part of the eigenvector matrix <m:math><m:semantics><m:mi>S</m:mi><m:annotation encoding="math/tex">S</m:annotation></m:semantics></m:math>: <m:math><m:semantics><m:mrow><m:mi>cos</m:mi><m:mo>⁡</m:mo><m:mo stretchy="false">(</m:mo><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi><m:mo stretchy="false">)</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mo>/</m:mo></m:mrow><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mrow><m:annotation encoding="math/tex">\cos(\frac{2\pi}{N}kn)/\sqrt{N}</m:annotation></m:semantics></m:math>.</caption>
          </subfigure>
          <subfigure id="dftsinMatrix-plot">
            <media id="dftsinMatrix" alt="Image">
              <image mime-type="image/png" src="../../media/imageigmat.png" width="200" print-width="200"/>
            </media>
            <caption>The real part of the eigenvector matrix <m:math><m:semantics><m:mi>S</m:mi><m:annotation encoding="math/tex">S</m:annotation></m:semantics></m:math>: <m:math><m:semantics><m:mrow><m:mi>sin</m:mi><m:mo>⁡</m:mo><m:mo stretchy="false">(</m:mo><m:mfrac><m:mrow><m:mn>2</m:mn><m:mi>π</m:mi></m:mrow><m:mi>N</m:mi></m:mfrac><m:mi>k</m:mi><m:mi>n</m:mi><m:mo stretchy="false">)</m:mo><m:mrow class="MJX-TeXAtom-ORD"><m:mo>/</m:mo></m:mrow><m:msqrt><m:mi>N</m:mi></m:msqrt></m:mrow><m:annotation encoding="math/tex">\sin(\frac{2\pi}{N}kn)/\sqrt{N}</m:annotation></m:semantics></m:math>.</caption>
          </subfigure>
          
        <caption>Graphical representation of the real and imaginary parts of the discrete-time finite length LTI system eigenvector matrix <m:math><m:semantics><m:mi>S</m:mi><m:annotation encoding="math/tex">S</m:annotation></m:semantics></m:math>.</caption></figure><para id="idm91539392880">
Likewise, we can plot the respective eigenvalues of the eigenvectors, which above we defined to be the values of the frequency response of the system:</para>
        <para id="idm91539392464"><m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi mathvariant="normal">Λ</m:mi><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:msub><m:mi>λ</m:mi><m:mn>0</m:mn></m:msub></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:msub><m:mi>λ</m:mi><m:mn>1</m:mn></m:msub></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd><m:mo>⋱</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd/><m:mtd><m:msub><m:mi>λ</m:mi><m:mrow class="MJX-TeXAtom-ORD"><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mtext> </m:mtext><m:mo>=</m:mo><m:mtext> </m:mtext><m:mrow><m:mo>[</m:mo><m:mtable rowspacing="4pt" columnspacing="1em"><m:mtr><m:mtd><m:msub><m:mi>H</m:mi><m:mi>u</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mn>0</m:mn><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:msub><m:mi>H</m:mi><m:mi>u</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mn>1</m:mn><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd><m:mo>⋱</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd/><m:mtd><m:msub><m:mi>H</m:mi><m:mi>u</m:mi></m:msub><m:mo stretchy="false">[</m:mo><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn><m:mo stretchy="false">]</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:annotation encoding="math/tex">\Lambda = \begin{bmatrix}  \lambda_0 \\ &amp; \lambda_1 \\ &amp;&amp; \ddots \\ &amp;&amp;&amp; \lambda_{N-1} \end{bmatrix}
~=~ \begin{bmatrix} H_u[0] \\ &amp; H_u[1] \\ &amp;&amp; \ddots \\ &amp;&amp;&amp; H_u[N-1] \end{bmatrix}</m:annotation></m:semantics></m:math>.</para>
        <para id="idm91539360528"> Putting the equation <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>y</m:mi><m:mo>=</m:mo><m:mi>H</m:mi><m:mi>x</m:mi></m:mrow><m:annotation encoding="math/tex">y=Hx</m:annotation></m:semantics></m:math> together with the decomposition <m:math xmlns:m="http://www.w3.org/1998/Math/MathML"><m:semantics><m:mrow><m:mi>H</m:mi><m:mo>=</m:mo><m:mi>S</m:mi><m:mi mathvariant="normal">Λ</m:mi><m:msup><m:mi>S</m:mi><m:mi>H</m:mi></m:msup></m:mrow><m:annotation encoding="math/tex">H=S\Lambda S^H</m:annotation></m:semantics></m:math>, we have:
</para>
        <figure id="ySLSxlti"><media id="ySLSxlti-plot" alt="Image">
            <image mime-type="image/png" src="../../media/diag.png" width="500" print-width="500"/>
          </media>
          
        <caption>Eigendecomposition of discrete-time finite length LTI systems.</caption></figure><para xmlns:m="http://www.w3.org/1998/Math/MathML" id="idm91539350480">We already know one way of understanding how LTI systems operate on signal inputs: they convolve them with the system's impulse response (represented in linear algebra form by the equation <m:math><m:semantics><m:mrow><m:mi>y</m:mi><m:mo>=</m:mo><m:mi>H</m:mi><m:mi>x</m:mi></m:mrow><m:annotation encoding="math/tex">y=Hx</m:annotation></m:semantics></m:math>, where <m:math><m:semantics><m:mi>H</m:mi><m:annotation encoding="math/tex">H</m:annotation></m:semantics></m:math> is circulant). The eigendecomposition gives us another understanding. The matrix <m:math><m:semantics><m:msup><m:mi>S</m:mi><m:mi>H</m:mi></m:msup><m:annotation encoding="math/tex">S^H</m:annotation></m:semantics></m:math> takes the input and extracts what would be the coefficients of the input's representation as a linear combination of harmonic sinusoids (it turns out this is called the discrete Fourier transform). Then, multiplication by the diagonal matrix <m:math><m:semantics><m:mi mathvariant="normal">Λ</m:mi><m:annotation encoding="math/tex">\Lambda</m:annotation></m:semantics></m:math> modifies these coefficients in a way that is particular to the system <m:math><m:semantics><m:mi>H</m:mi><m:annotation encoding="math/tex">H</m:annotation></m:semantics></m:math> (all LTI systems have the same <m:math><m:semantics><m:mi>S</m:mi><m:annotation encoding="math/tex">S</m:annotation></m:semantics></m:math> and <m:math><m:semantics><m:msup><m:mi>S</m:mi><m:mi>H</m:mi></m:msup><m:annotation encoding="math/tex">S^H</m:annotation></m:semantics></m:math>). Finally, multiplication with the matrix <m:math><m:semantics><m:mi>S</m:mi><m:annotation encoding="math/tex">S</m:annotation></m:semantics></m:math> takes the modified coefficients and expresses them as a linear combination of harmonic sinusoids to give the output <m:math><m:semantics><m:mi>y</m:mi><m:annotation encoding="math/tex">y</m:annotation></m:semantics></m:math> (it turns out that operation is called the inverse discrete Fourier transform).</para>
    </section>
  </content>
</document>